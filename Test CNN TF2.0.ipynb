{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **CNN using TensorFlow 2.0**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook aims to learn how to use Convolutional Neural Networks (CNN) using TensorFlow 2.0.\n",
    "\n",
    "Thus, we will use the MNIST dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Imports and preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we will use TensorBoard to visualize the training of the CNN, we have to import it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard.notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We remove the previous logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf ./logs/ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports : \n",
    "* TensorFlow 2.0 ( pip install tensorflow==2.0.0-alpha0 OR pip install tensorflow-gpu==2.0.0-alpha0 )\n",
    "* Datetime ( pip install DateTime )\n",
    "* Os ( already in Python's standard library )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import datetime\n",
    "import os\n",
    "from tensorflow.keras import datasets, layers, models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Building the CNN object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN():\n",
    "    # As you give images to a CNN, the size of the images, and the amount of their channels must be fixed.\n",
    "    # When initializing, the model is not generated yet, and so is the TensorBoard callback.\n",
    "    def __init__(self, img_width, img_height, channels):\n",
    "        self.img_width = img_width\n",
    "        self.image_height = img_height\n",
    "        self.channels = channels\n",
    "        self.model = None\n",
    "        self.tb_callback = None\n",
    "    \n",
    "    # When generating the model, we give some parameters so that we can customize the CNN as we want\n",
    "    # Yet, we can customize the dropout rate, and the depth of each convolutional layer\n",
    "    def gen_model(self, dropout=0.2, depth=32):\n",
    "        self.model = models.Sequential()\n",
    "        \n",
    "        self.model.add(layers.Conv2D(depth, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "        self.model.add(layers.MaxPooling2D((2, 2)))\n",
    "        self.model.add(layers.Dropout(dropout))\n",
    "        \n",
    "        self.model.add(layers.Conv2D(depth*2, (3, 3), activation='relu'))\n",
    "        self.model.add(layers.MaxPooling2D((2, 2)))\n",
    "        self.model.add(layers.Dropout(dropout))\n",
    "        \n",
    "        self.model.add(layers.Conv2D(depth*2, (3, 3), activation='relu'))\n",
    "        self.model.add(layers.Flatten())\n",
    "        self.model.add(layers.Dense(depth*2, activation='relu'))\n",
    "        self.model.add(layers.Dense(10, activation='softmax'))\n",
    "        \n",
    "        self.model.summary()\n",
    "        \n",
    "        return self.model\n",
    "    \n",
    "    # To train the model using supervised learning, you have to give the model some data, and the labels of these data\n",
    "    # You can also specify a different optimizer than Adam (which is like a better gradient descent), a different calculation\n",
    "    # of the loss (measure of the error to minimize), if you want to use TensorBoard to visualize the training session, and the \n",
    "    # amont of epochs.\n",
    "    def train(self,\n",
    "              train_images, \n",
    "              train_labels,\n",
    "              optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              tensorboard=True,\n",
    "              epochs=10\n",
    "              ):\n",
    "        \n",
    "        self.model.compile(optimizer=optimizer, loss=loss,  metrics=['accuracy'])\n",
    "        \n",
    "        if tensorboard:\n",
    "            log_dir=\"logs\" + os.sep + \"fit\" + os.sep + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "            self.tb_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "            self.model.fit(train_images, train_labels, epochs=epochs, callbacks=[self.tb_callback])\n",
    "        else:\n",
    "            self.model.fit(train_images, train_labels, epochs=epochs)\n",
    "  \n",
    "    # To evaluate the model, you have to give the model some data (and their labels) that he has NEVER SEEN during the training,\n",
    "    # as we want it to learn a general meaning of the data, and not some bias specific to the training dataset.\n",
    "    def evaluate(self,test_images, test_labels):\n",
    "        test_loss, test_acc = self.model.evaluate(test_images, test_labels)\n",
    "        print(\"Loss : \\n {}\".format(test_loss))\n",
    "        print(\"Accuracy : \\n {}\".format(test_acc)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Loading the training and test datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To keep it simple, we will use the very classic MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshaping the data so the shape is compatible with our CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape((60000, 28, 28, 1))\n",
    "test_images = test_images.reshape((10000, 28, 28, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Generating and training the CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialization and generation of the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                36928     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 93,322\n",
      "Trainable params: 93,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.sequential.Sequential at 0x7fac865accf8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn = CNN(28,28,1)\n",
    "cnn.gen_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the CNN using the MNIST training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 6s 101us/sample - loss: 0.3400 - accuracy: 0.9165\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 5s 82us/sample - loss: 0.0825 - accuracy: 0.9743\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 5s 83us/sample - loss: 0.0677 - accuracy: 0.9793\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 5s 83us/sample - loss: 0.0605 - accuracy: 0.9815\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 5s 84us/sample - loss: 0.0530 - accuracy: 0.9834\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 5s 84us/sample - loss: 0.0457 - accuracy: 0.9859\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 5s 84us/sample - loss: 0.0430 - accuracy: 0.9873\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 5s 85us/sample - loss: 0.0422 - accuracy: 0.9877\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 5s 84us/sample - loss: 0.0405 - accuracy: 0.9883\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 5s 84us/sample - loss: 0.0373 - accuracy: 0.9891\n"
     ]
    }
   ],
   "source": [
    "cnn.train(train_images, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the training logs using TensorBoard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"800\"\n",
       "            src=\"http://localhost:6006\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fac865acc50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, to use TensorBoard, open a terminal and write the following line : \n",
    "* tensorboard --logdir=./logs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_garridoq",
   "language": "python",
   "name": "tf_garridoq"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
